{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd7d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 20:35:29.152518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 20:35:29.317426: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-02 20:35:40.178273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/gmp/6.2.1/b1/lib:/software/glpk/4.65/lib:/software/zmq/4.2.3/b1/lib:/software/git/2.30.1/lib64:/software/gcc/7.3.0/lib64:/software/gcc/7.3.0/lib:/software/openmpi/4.0.4/b1/lib:/software/cuda/11.4/usr/local/cuda-11.4/lib64:/software/cuda/11.4/usr/local/cuda-11.4/targets/x86_64-linux/lib:/software/cudnn/11.4-8.2.4.15/lib64:/software/slurm/current/lib64:/software/slurm/current/lib\n",
      "2023-03-02 20:35:40.178475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/gmp/6.2.1/b1/lib:/software/glpk/4.65/lib:/software/zmq/4.2.3/b1/lib:/software/git/2.30.1/lib64:/software/gcc/7.3.0/lib64:/software/gcc/7.3.0/lib:/software/openmpi/4.0.4/b1/lib:/software/cuda/11.4/usr/local/cuda-11.4/lib64:/software/cuda/11.4/usr/local/cuda-11.4/targets/x86_64-linux/lib:/software/cudnn/11.4-8.2.4.15/lib64:/software/slurm/current/lib64:/software/slurm/current/lib\n",
      "2023-03-02 20:35:40.178483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59de2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVADI\n",
      "LRIQV\n",
      "WIFIR\n",
      "ITLIG\n",
      "LVMGP\n",
      "LFAEI\n",
      "IFTAV\n",
      "VQFIR\n",
      "YTLVA\n",
      "LHMGP\n",
      "VMAEI\n",
      "ILTEV\n",
      "WMKIY\n",
      "IHLYA\n",
      "ALMIP\n",
      "LHAII\n",
      "ITTEV\n",
      "WSKIY\n",
      "TLLYA\n",
      "ILMIP\n",
      "VVAII\n",
      "LVTEV\n",
      "WMNIG\n",
      "LNLYM\n",
      "WMMMP\n",
      "VTALI\n",
      "IYTPV\n",
      "WTQIL\n",
      "VLLYP\n",
      "VLMQP\n",
      "LYANI\n",
      "YITTV\n",
      "WTQIT\n",
      "IFLYS\n",
      "VMMQP\n",
      "IRAQI\n",
      "IRTYV\n",
      "WVRID\n",
      "VMLYS\n",
      "TEMVP\n",
      "MYARI\n",
      "MNVIV\n",
      "WMRII\n",
      "IVLYT\n",
      "ILFIP\n",
      "SYASI\n",
      "WSVLV\n",
      "WITIG\n",
      "PMMIA\n",
      "IVFVP\n",
      "LVATI\n",
      "MHVQV\n",
      "WVTIN\n",
      "VVMYS\n",
      "VIFVP\n",
      "LYATI\n",
      "LRVRV\n",
      "WTVIT\n",
      "VTMYT\n",
      "IIFYP\n",
      "MYATI\n",
      "LHVSV\n",
      "WVYIG\n",
      "VVMYT\n",
      "MYATI\n",
      "LRVSV\n",
      "WMYIQ\n",
      "IITIG\n",
      "YAATI\n",
      "WMYQV\n",
      "WVYIR\n",
      "IKTYP\n",
      "LNAVI\n",
      "LRAKL\n",
      "WMQLS\n",
      "IMTYP\n",
      "LRAVI\n",
      "IVAML\n",
      "WVRLE\n",
      "ITTYP\n",
      "ISIEI\n",
      "VIAQL\n",
      "WMRLI\n",
      "YVTYT\n",
      "LNIVI\n",
      "LRMQL\n",
      "ITRLV\n",
      "LYLQI\n",
      "IQMVL\n",
      "WMRLY\n",
      "LNMTI\n",
      "IVTLL\n",
      "WTSLA\n",
      "IFTAI\n",
      "VNTTL\n",
      "WTSLQ\n",
      "YVTAI\n",
      "IAVEL\n",
      "WTSLY\n",
      "IMTDI\n",
      "IRVEL\n",
      "WMTLN\n",
      "IYTDI\n",
      "VAVEL\n",
      "WTVLY\n",
      "VYTEI\n",
      "IQVML\n",
      "WTYLF\n",
      "IMTII\n",
      "IQVML\n",
      "WTYLI\n",
      "VTTII\n",
      "INVQL\n",
      "WMYLT\n",
      "VTTLI\n",
      "VTVQL\n",
      "WMYLY\n",
      "VYTQI\n",
      "MNVTL\n",
      "WMRMN\n",
      "ISTYI\n",
      "RAIVM\n",
      "WTVTS\n",
      "ITTYI\n",
      "LYATF\n",
      "WIYTR\n",
      "INVEI\n",
      "LNMTF\n",
      "WVYTY\n",
      "IHVMI\n",
      "MSMVF\n",
      "WTQYV\n",
      "INVQI\n",
      "YNMVF\n",
      "WMRYQ\n",
      "IWVSI\n",
      "LYTSF\n",
      "WTSYT\n",
      "LRVSI\n",
      "LNVIF\n",
      "LTVTI\n",
      "LNVLF\n",
      "IIVVI\n",
      "ITLVY\n",
      "LYAQV\n",
      "LRLVY\n",
      "INIEV\n",
      "QMYLY\n",
      "ISIEV\n",
      "LYYQY\n"
     ]
    }
   ],
   "source": [
    "pos_ohe_data = np.load(\"positive.npy\",  allow_pickle=True)\n",
    "neg_ohe_data = np.load(\"negative.npy\",  allow_pickle=True)\n",
    "\n",
    "def ohe_to_seq(ohe_pep):\n",
    "    alphabet = ['A','R','N','D','C','Q','E','G','H','I', 'L','K','M','F','P','S','T','W','Y','V']\n",
    "    seq = ''\n",
    "    # expect a 2D numpy array (pep_length x 20), give the string it represents\n",
    "    for letter in ohe_pep[:int(np.sum(ohe_pep))]:\n",
    "        idx = np.argmax(letter)\n",
    "        if letter[idx] == 0:\n",
    "            break\n",
    "        seq += alphabet[idx]\n",
    "    return(seq)\n",
    "\n",
    "for vec in (pos_ohe_data):\n",
    "    print(ohe_to_seq(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b876cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNs_found = np.load('../saved_models/shp2-rnn/spy_RNs_sampling.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77530ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('../saved_models/shp2-rnn/spy_model.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights('../saved_models/shp2-rnn/spy_model_weights.h5') \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82fb4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 190)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(RNs_found, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b751b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 20:41:04.880086: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 20:41:05.813108: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "def counts_aa(vec):\n",
    "    counts =  tf.histogram_fixed_width(vec, [0, 20], nbins=21)[1:]\n",
    "    return counts /tf.reduce_sum(counts)\n",
    "\n",
    "y_hat_RN = loaded_model.predict([RNs_found, np.array([counts_aa(xi) for xi in RNs_found])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4b65dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.,  8.,  3.,  4.,  7.,  7., 15., 14., 19., 77.]),\n",
       " array([0.07072526, 0.16188726, 0.25304925, 0.34421128, 0.43537328,\n",
       "        0.5265353 , 0.6176973 , 0.70885926, 0.8000213 , 0.89118326,\n",
       "        0.9823453 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_hat_RN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2800eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(seq_vector):\n",
    "  alphabet = ['A','R','N','D','C','Q','E','G','H','I', 'L','K','M','F','P','S','T','W','Y','V']\n",
    "  seq = []\n",
    "  for i, index in enumerate(seq_vector.astype('int')):\n",
    "    if index == 0:\n",
    "      break\n",
    "    seq.append(alphabet[index-1])\n",
    "  seq = ''.join(seq)\n",
    "  return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0019d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_sorted = np.argsort(y_hat_RN,axis=0)\n",
    "# 5 most probable RN\n",
    "most_likely_RN =  RNs_found[indices_sorted][:5]\n",
    "# 5 least probable RN\n",
    "least_likely_RN =  RNs_found[indices_sorted][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b96b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0707215 ],\n",
       "       [0.08515194],\n",
       "       [0.09033306],\n",
       "       [0.09328519],\n",
       "       [0.09549117]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict([most_likely_RN.squeeze(), np.array([counts_aa(xi) for xi in most_likely_RN.squeeze()])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7d4b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YYASE\n",
      "QVRAK\n",
      "VANAT\n",
      "NVAAT\n",
      "TFGRM\n"
     ]
    }
   ],
   "source": [
    "for vec in most_likely_RN:\n",
    "    print(decoder(vec[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d179bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WVLYA\n",
      "AVITW\n",
      "TWIYT\n",
      "WITAV\n",
      "IFLYW\n"
     ]
    }
   ],
   "source": [
    "for vec in least_likely_RN:\n",
    "    print(decoder(vec[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf64827",
   "metadata": {},
   "source": [
    "## Test against PN classifier trained on SHP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c5bbee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('../saved_models/shp2-rnn/PN_model.json', 'r')\n",
    "PN_loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "PN_loaded_model = tf.keras.models.model_from_json(PN_loaded_model_json)\n",
    "# load weights into new model\n",
    "PN_loaded_model.load_weights('../saved_models/shp2-rnn/PN_model_weights.h5') \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a656d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.8908055],\n",
       "       [-4.457416 ],\n",
       "       [-4.6339006],\n",
       "       [-4.9624224],\n",
       "       [-3.6902256]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PN_loaded_model.predict([most_likely_RN.squeeze(), np.array([counts_aa(xi) for xi in most_likely_RN.squeeze()])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83128e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.7693696],\n",
       "       [2.7280474],\n",
       "       [2.8132837],\n",
       "       [3.050894 ],\n",
       "       [1.8668313]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PN_loaded_model.predict([least_likely_RN.squeeze(), np.array([counts_aa(xi) for xi in least_likely_RN.squeeze()])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0309b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "serverless"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
